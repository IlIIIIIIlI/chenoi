{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ce0a76",
   "metadata": {},
   "source": [
    "# 个贷违约"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddec8e",
   "metadata": {},
   "source": [
    "PDF请访问[个贷违约预测.pdf](https://www.dropbox.com/s/ms0sefr2sulvmdg/L3%20%E4%B8%AA%E8%B4%B7%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B1V0.2.pptx?dl=0)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e484a7",
   "metadata": {},
   "source": [
    "## 使用autoML模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 用autoML 来找最佳的metric - path 只是model信息保存的文件路径\n",
    "# model = TabularPredictor(label=\"subscribe\", eval_metric='f1', path=\"model_simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 获取模型各个feature的重要性\n",
    "# model.feature_metadata_in.get_features()\n",
    "# model.feature_importance(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014e175",
   "metadata": {},
   "source": [
    " ## 特征工程：考虑每个feature实际的重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65723f5c",
   "metadata": {},
   "source": [
    "### 一种numeric格式转换成categoric的格式的方式\n",
    "for a list of pred, makes it be a human-readable labels and input to a dataframe as a column\n",
    "\n",
    "y_pred = [1 if x >= 0.5 else 0 for x in y_pred]\n",
    "\n",
    "subscribe_map = {1.0:\"yes\", 0.0:\"no\"}\n",
    "\n",
    "result['subscribe'] = [subscribe_map[x] for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dacc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一位按照年加进去\n",
    "def f(x):\n",
    "    try:\n",
    "        x1, x2, x3 = x.split('-')\n",
    "        if x1 == '2022':\n",
    "            x = str(int(x3) + 2000) + '/' + x2  + '/' + '1'\n",
    "    except Exception:\n",
    "        x == x\n",
    "    return x\n",
    "train_public['earlies_credit_mon'] = train_public['earlies_credit_mon'].apply(f)\n",
    "test_public['earlies_credit_mon'] = test_public['earlies_credit_mon'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f8031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cat(data):\n",
    "    # \tclass\temployer_type\tindustry\twork_year\n",
    "    # 先看class有多少类\n",
    "    class_map = {'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}\n",
    "    yr_map = {'< 1 year':0, '1 years':1, '2 years':2, '3 years':3, '4 years':4, '5 years':5, '6 years':6, '7 years':7, '8 years':8, '9 years':9, '10+ years':10}\n",
    "    industry_map = {'金融业':0, '房地产业':0, '电力、热力生产供应业':1, '制造业':1, '建筑业':1, '交通运输、仓储和邮政业':1, '农、林、牧、渔业':2, '采矿业':2, '批发和零售业':3, '住宿和餐饮业':3, '文化和体育业':3, '公共服务、社会组织':4, '国际组织':4, '信息传输、软件和信息技术服务业':5}\n",
    "    emp_map = {'普通企业':0, '政府机构':1, '世界五百强':3, '高等教育机构':1, '上市企业':2, '幼教与中小学校':1}\n",
    "    '''\n",
    "    单纯的用于表示cat的numeric变成程度关联\n",
    "        金融业                122758\n",
    "        电力、热力生产供应业   92072\n",
    "        公共服务、社会组织     77326\n",
    "        住宿和餐饮业           68422\n",
    "        文化和体育业           61548\n",
    "        信息传输、软件和信息技术服务业     61023\n",
    "        建筑业                53330\n",
    "        房地产业              45733\n",
    "        交通运输、仓储和邮政业 38300\n",
    "        采矿业                38092\n",
    "        农、林、牧、渔业       38091\n",
    "        国际组织              22909\n",
    "        批发和零售业          22738\n",
    "        制造业                22658\n",
    "        普通企业             347404\n",
    "        政府机构             197443\n",
    "        幼教与中小学校        76547\n",
    "        上市企业             76425\n",
    "        世界五百强           41361\n",
    "        高等教育机构         25820\n",
    "    '''\n",
    "    # 其他几个类用labelencoder\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "#     data['employer_type'] = le.fit_transform(data['employer_type'])\n",
    "    data['industry'] = le.fit_transform(data['industry'])\n",
    "#     data['industry'] = data['industry'].map(industry_map)\n",
    "    data['class'] = data['class'].map(class_map)\n",
    "    data['work_year'] = data['work_year'].map(yr_map)\n",
    "    data['employer_type'] = data['employer_type'].map(emp_map)\n",
    "    \n",
    "    # 看到有时间，就先处理时间类型\n",
    "    import datetime\n",
    "    data['earlies_credit_mon'] = pd.to_datetime(data['earlies_credit_mon'])\n",
    "    # 时间多尺度, 都是月度时间，用value_counts()可以看到日期日的话都是1\n",
    "    data['earlies_credit_mon_yr'] = data['earlies_credit_mon'].dt.year\n",
    "    data['earlies_credit_mon_mt'] = data['earlies_credit_mon'].dt.month\n",
    "\n",
    "    # 将时间转换成时间区间\n",
    "    # 首先设置basetime\n",
    "    basetime1 = data['earlies_credit_mon'].min()\n",
    "    data['earlies_credit_mon_diffs'] = data['earlies_credit_mon'].apply(lambda x:x-basetime1).dt.days\n",
    "    # train['issue_date_diffs']\n",
    "\n",
    "    data['issue_date'] = pd.to_datetime(data['issue_date'])\n",
    "    # 时间多尺度, 都是月度时间，用value_counts()可以看到日期日的话都是1\n",
    "    data['issue_year'] = data['issue_date'].dt.year\n",
    "    data['issue_month'] = data['issue_date'].dt.month\n",
    "\n",
    "    # 将时间转换成时间区间\n",
    "    # 首先设置basetime\n",
    "    basetime2 = data['issue_date'].min()\n",
    "    data['issue_date_diffs'] = data['issue_date'].apply(lambda x:x-basetime2).dt.days\n",
    "    # train['issue_date_diffs']\n",
    "    \n",
    "    # drop多余的列\n",
    "    # data.drop(['issue_date', 'earlies_credit_mon'], axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65dff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果打印出来这两个table， 发现有些feature是一样的但是名字不一样\n",
    "train_public = train_public.rename(columns={'isDefault':'is_default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2840f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查找数据集ab \n",
    "common_cols = []\n",
    "for col in train_public.columns:\n",
    "    if col in train_internet:\n",
    "        common_cols.append(col)\n",
    "len(common_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d60e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f5', 'house_loan_status', 'marriage', 'sub_class', 'offsprings', 'work_type'}\n"
     ]
    }
   ],
   "source": [
    "print(set(train_internet.columns) - set(common_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695f60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_internet = train_internet.drop(['work_type', 'marriage', 'sub_class', 'f5', 'house_loan_status', 'offsprings'], axis=1)\n",
    "for col in ['known_outstanding_loan', 'app_type', 'known_dero']:\n",
    "    train_internet[col] = np.nan\n",
    "\n",
    "# 增加 is_internet 字段\n",
    "train_internet['is_internet'] = True\n",
    "train_public['is_internet'] = False\n",
    "test_public['is_internet'] = False\n",
    "\n",
    "# 拼接所有数据\n",
    "df = pd.concat([train_public, test_public, train_internet]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983981ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_cat(df)\n",
    "\n",
    "# ---------- # \n",
    "'''['loan_id', 'user_id', 'total_loan', 'year_of_loan', 'interest',\n",
    "       'monthly_payment', 'class', 'employer_type', 'industry', 'work_year',\n",
    "       'house_exist', 'censor_status', 'issue_date', 'use', 'post_code',\n",
    "       'region', 'debt_loan_ratio', 'del_in_18month', 'scoring_low',\n",
    "       'scoring_high', 'pub_dero_bankrup', 'early_return',\n",
    "       'early_return_amount', 'early_return_amount_3mon', 'recircle_b',\n",
    "       'recircle_u', 'initial_list_status', 'earlies_credit_mon', 'title',\n",
    "       'policy_code', 'f0', 'f1', 'f2', 'f3', 'f4', 'is_default',\n",
    "       'known_outstanding_loan', 'app_type', 'known_dero', 'is_internet'],\n",
    "'''\n",
    "\n",
    "df['monthly_loan_rb'] = df['monthly_payment'] * 12 * df['year_of_loan'] / (df['recircle_b'] + 0.1)\n",
    "# 单位循环额度利用率\n",
    "df['rurb'] = df['recircle_u'] / (df['recircle_b'] + 0.1)\n",
    "# debt_loan_ratio 债务收入比\n",
    "# 对于 <0 的异常值进行处理 ==》 转换为正数\n",
    "df['debt_loan_ratio'] = np.abs(df['debt_loan_ratio']).fillna(df['debt_loan_ratio'].mean())\n",
    "# recircle_b_total_loan 信贷额度周转率\n",
    "df['recircle_b_total_loan'] = df['recircle_b'] / (df['total_loan'] + 0.1)\n",
    "# recircle_b_monthly_pmt 分期付款金额\n",
    "df['recircle_bmp'] = df['recircle_b'] / (df['monthly_payment'] + 0.1)\n",
    "# 空缺情况, =1 统计有多少空列 =0 统计有多少空行\n",
    "df['nulls'] = df.isnull().sum(axis=1)\n",
    "# 平均每年贷款金额\n",
    "df['avg_loan'] = df['total_loan'] / df['year_of_loan']\n",
    "# 平均每年贷款利率\n",
    "df['mean_interest'] = df['interest'] / df['year_of_loan']\n",
    "# 总计还款金额\n",
    "df['all_monthly_pmt'] = df['monthly_payment'] * df['year_of_loan']\n",
    "# rest_known_zero 剩余公开记录的数量\n",
    "df['rest_known_dero'] = df['known_dero'] - df['pub_dero_bankrup']\n",
    "# 除信贷周转余额外，剩余贷款数额\n",
    "df['rest_loan_recircle_b'] = df['total_loan'] - df['recircle_b']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0af5c",
   "metadata": {},
   "source": [
    "## 数据分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b75f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不适合太多， 稳定性， 每个分箱的样本数 > 5%\n",
    "# df.groupby(['industry'])['is_default'].mean()\n",
    "bin_number = 12\n",
    "label_list = list(range(bin_number))\n",
    "df['total_loan_bin'] = pd.qcut(df['total_loan'], bin_number, labels=label_list, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b2a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_internet_f = df[df['is_internet'] == False].copy()\n",
    "df_internet_t = df[df['is_internet'] == True].copy()\n",
    "\n",
    "db_train = df_internet_f[df_internet_f['is_default'].notnull()]\n",
    "db_test = df_internet_f[df_internet_f['is_default'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c42156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select_dtypes(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8adf86d",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8d27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([db_train, df_internet_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54bb375e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./model\"\n",
      "Beginning AutoGluon training ... Time limit = 500s\n",
      "AutoGluon will save models to \"./model\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.3\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    760000\n",
      "Train Data Columns: 56\n",
      "Label Column: is_default\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0.0, 1.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5099.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 326.8 MB (6.4% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 6.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['policy_code']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])     :  1 | ['is_internet']\n",
      "\t\t('category', []) :  1 | ['total_loan_bin']\n",
      "\t\t('datetime', []) :  2 | ['issue_date', 'earlies_credit_mon']\n",
      "\t\t('float', [])    : 31 | ['total_loan', 'interest', 'monthly_payment', 'work_year', 'post_code', ...]\n",
      "\t\t('int', [])      : 20 | ['loan_id', 'user_id', 'year_of_loan', 'class', 'employer_type', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             :  1 | ['total_loan_bin']\n",
      "\t\t('float', [])                : 31 | ['total_loan', 'interest', 'monthly_payment', 'work_year', 'post_code', ...]\n",
      "\t\t('int', [])                  : 18 | ['loan_id', 'user_id', 'class', 'employer_type', 'industry', ...]\n",
      "\t\t('int', ['bool'])            :  3 | ['year_of_loan', 'initial_list_status', 'is_internet']\n",
      "\t\t('int', ['datetime_as_int']) :  8 | ['issue_date', 'issue_date.year', 'issue_date.month', 'issue_date.dayofweek', 'earlies_credit_mon', ...]\n",
      "\t5.7s = Fit runtime\n",
      "\t55 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 328.32 MB (6.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.77s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 752400, Val Rows: 7600\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost ... Training model for up to 493.23s of the 493.23s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 2.483 GB, but only 4.867 GB is available...\n",
      "\tRan out of time, early stopping on iteration 1499.\n",
      "\t0.7969\t = Validation score   (roc_auc)\n",
      "\t493.63s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the -0.48s of remaining time.\n",
      "\t0.7969\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 501.64s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./model\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0             CatBoost   0.796899       0.015957  493.625306                0.015957         493.625306            1       True          1\n",
      "1  WeightedEnsemble_L2   0.796899       0.018947  493.631290                0.002990           0.005985            2       True          2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.796899</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>493.625306</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>493.625306</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.796899</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>493.631290</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val  pred_time_val    fit_time  \\\n",
       "0             CatBoost   0.796899       0.015957  493.625306   \n",
       "1  WeightedEnsemble_L2   0.796899       0.018947  493.631290   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.015957         493.625306            1       True   \n",
       "1                0.002990           0.005985            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "model_autogluon = TabularPredictor(label='is_default',eval_metric='roc_auc', path=\"./model\")\n",
    "model_autogluon.fit(data, time_limit=500, hyperparameters = {\n",
    "#                'GBM': {'num_boost_round': 5000},\n",
    "               'CAT': {'iterations': 2000},\n",
    "#                'XT': {'n_estimators': 300},\n",
    "})\n",
    "model_autogluon.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "952e3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model_autogluon.predict_proba(db_test)[1]\n",
    "result = pd.DataFrame(columns=['id', 'isDefault'])\n",
    "result['id'] = db_test['loan_id']\n",
    "result['isDefault'] = y_pred\n",
    "result.to_csv('/Users/19723/Desktop/baseline_autogluon6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e848f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['is_default'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "# model_lgb = lgb.LGBMClassifier(n_estimators=500)\n",
    "xgb_lgb = xgb.XGBClassifier(learning_rate=0.1, n_estimators=150, gamma=0,subsample=0.8, colsample_bytree=0.8, max_depth=7, random_state=2022, enable_categorical=True)\n",
    "# model_Cat = CatBoostClassifier(iterations=5000, depth=7, learning_rate=0.001, loss_function='Logloss', eval_metric='AUC', logging_level='Verbose', metric_period=50)\n",
    "# 模型训练\n",
    "labels = data['is_default']\n",
    "xgb_lgb.fit(data.drop(['is_default'], axis=1), labels)\n",
    "y_pred = xgb_lgb.predict_proba(db_test)\n",
    "result = pd.DataFrame(columns=['id', 'isDefault'])\n",
    "result['id'] = test['loan_id']\n",
    "result['isDefault'] = y_pred[:,1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d314ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}